name: Live Security Pipeline (AI-Powered Multi-Secret Remediation)

on:
  push:
    branches: [main] # Main 브랜치에 푸시될 때 실행

jobs:
  ai-security-job:
    runs-on: ubuntu-latest
    
    steps:
      # ============================================
      # 1. 소스코드 체크아웃
      # ============================================
      - name: Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # TruffleHog가 전체 히스토리를 스캔하도록 함

      # ============================================
      # 2. Python, TruffleHog 및 의존성 설치
      # ============================================
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install Dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          pip install gdown # gdown 설치

      - name: Install TruffleHog
        run: |
          curl -sSfL https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/scripts/install.sh | sh -s -- -b /usr/local/bin
          trufflehog --version

      # ============================================
      # 3. AI 모델 다운로드
      # ============================================
      - name: Download AI Model from Google Drive
        env:
          MODEL_GDRIVE_ID: 1ylZK77oDPfjKncHXPiu5Iuzw_XeLltU5
        run: |
          echo " Downloading AI model..."
          mkdir -p models
          gdown $MODEL_GDRIVE_ID -O models/model.pt
          
          if [ ! -f "models/model.pt" ]; then
            echo " AI Model download failed"
            exit 1
          fi
          echo " Model downloaded successfully"

      # ============================================
      # 4. TruffleHog 1차 스캔
      # ============================================
      - name: Run TruffleHog Scan (1st Detection)
        id: scan
        run: |
          echo " Scanning for leaks..."
          SCAN_PATH="./remediation-test/" # 레포지토리 전체 스캔
          
          # outputs 디렉토리 생성
          mkdir -p outputs
          
          trufflehog filesystem $SCAN_PATH --json > outputs/trufflehog_results.json
          
          # results.json도 생성
          cp outputs/trufflehog_results.json results.json
          
          # 스캔 결과가 비어있는지 확인
          if [ ! -s results.json ]; then
            echo " No findings found by TruffleHog."
            echo "findings_exist=false" >> $GITHUB_OUTPUT
            echo "[]" > outputs/trufflehog_results.json
          else
            echo " Found potential findings. Proceeding to AI filter."
            echo "findings_exist=true" >> $GITHUB_OUTPUT
            cat results.json | head -n 5
          fi

      # ============================================
      #  Artifact: TruffleHog 1차 스캔 결과
      # ============================================
      - name: Upload TruffleHog Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: 01-trufflehog-scan-results
          path: outputs/trufflehog_results.json
          retention-days: 30

      # ============================================
      # 5. 결과 파싱 (Parser 실행)
      # ============================================
      - name: Parse TruffleHog Results
        if: steps.scan.outputs.findings_exist == 'true'
        run: |
          echo " Parsing results for AI..."
          python src/parser.py results.json -o outputs/parsed_results.json

      # ============================================
      #  Artifact: 파싱된 결과
      # ============================================
      - name: Upload Parsed Results
        uses: actions/upload-artifact@v4
        if: steps.scan.outputs.findings_exist == 'true'
        with:
          name: 02-parsed-results
          path: outputs/parsed_results.json
          retention-days: 30

      # ============================================
      # 6. AI 모델 필터링 (2차 탐지)
      # ============================================
      - name: Run AI Model Prediction (2nd Detection)
        if: steps.scan.outputs.findings_exist == 'true'
        run: |
          echo " Running AI filter..."
          python src/ai_filter.py \
            -i outputs/parsed_results.json \
            -m models/model.pt \
            -o outputs/predictions.json \
            --confidence-threshold 0.70
          cp outputs/predictions.json predictions.json

      # ============================================
      #  Artifact: AI 예측 결과
      # ============================================
      - name: Upload AI Predictions
        uses: actions/upload-artifact@v4
        if: steps.scan.outputs.findings_exist == 'true'
        with:
          name: 03-ai-predictions
          path: outputs/predictions.json
          retention-days: 30
          

      # ============================================
      # 7.  최종 확인 (다중 시크릿 확인)
      # ============================================
      - name: Check for Confirmed AI Findings
        id: check_ai_results
        if: steps.scan.outputs.findings_exist == 'true'
        run: |
          echo " Checking AI prediction results..."
          
          # Python으로 안전하게 분석 (null-safe)
          python3 << 'EOF'
          import json
          import os
          import re
          from datetime import datetime
          
          # predictions.json 로드
          with open('predictions.json', 'r', encoding='utf-8') as f:
              data = json.load(f)
          
          findings = data.get('findings', [])
          
          # 확인된 시크릿 필터링 (null-safe)
          confirmed_secrets = []
          confirmed_aws = []
          confirmed_general = []
          
          for finding in findings:
              pred = finding.get('deberta_prediction')
              if not pred:
                  continue
              
              # AI가 Y(진짜 시크릿)로 판단한 경우
              if pred.get('label') == 'Y':
                  confirmed_secrets.append(finding)
                  
                  # secret_type 확인 (null-safe)
                  secret_type = finding.get('secret_type', '') or finding.get('category', '')
                  
                  # AWS 관련 시크릿인지 확인
                  if re.search(r'AWS|Amazon', secret_type, re.IGNORECASE):
                      confirmed_aws.append(finding)
                  else:
                      confirmed_general.append(finding)
          
          # 통계
          confirmed_total = len(confirmed_secrets)
          confirmed_aws_count = len(confirmed_aws)
          confirmed_general_count = len(confirmed_general)
          
          # 분석 리포트 생성
          timestamp = datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC")
          
          with open('outputs/analysis_report.txt', 'w', encoding='utf-8') as f:
              f.write("=== AI Filter Analysis Report ===\n")
              f.write(f"Timestamp: {timestamp}\n")
              f.write("\n")
              f.write(f"Total Confirmed Secrets: {confirmed_total}\n")
              f.write(f"  - AWS Keys: {confirmed_aws_count}\n")
              f.write(f"  - General Secrets: {confirmed_general_count}\n")
          
          # 확인된 시크릿 목록 저장
          with open('outputs/confirmed_secrets.json', 'w', encoding='utf-8') as f:
              json.dump(confirmed_secrets, f, indent=2)
          
          # 결과 출력 및 GitHub Actions 변수 설정
          if confirmed_total > 0:
              print(f" DANGER: Found {confirmed_total} confirmed secrets!")
              print(f"  - AWS Keys: {confirmed_aws_count} (will be auto-deactivated)")
              print(f"  - General Secrets: {confirmed_general_count} (manual review required)")
              
              with open('outputs/analysis_report.txt', 'a', encoding='utf-8') as f:
                  f.write("Status: CRITICAL - Remediation required\n")
              
              # GitHub Actions output 설정
              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                  f.write("secrets_detected=true\n")
                  f.write(f"confirmed_total={confirmed_total}\n")
                  f.write(f"confirmed_aws={confirmed_aws_count}\n")
                  f.write(f"confirmed_general={confirmed_general_count}\n")
          else:
              print(" AI filter confirmed no active secrets.")
              
              with open('outputs/analysis_report.txt', 'a', encoding='utf-8') as f:
                  f.write("Status: SAFE - No active secrets detected\n")
              
              # GitHub Actions output 설정
              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                  f.write("secrets_detected=false\n")
                  f.write("confirmed_total=0\n")
                  f.write("confirmed_aws=0\n")
                  f.write("confirmed_general=0\n")
          
          print(f"\n Analysis Summary:")
          print(f"  Total: {confirmed_total}")
          print(f"  AWS: {confirmed_aws_count}")
          print(f"  General: {confirmed_general_count}")
          EOF

      # ============================================
      #  Artifact: 분석 리포트
      # ============================================
      - name: Upload Analysis Report
        uses: actions/upload-artifact@v4
        if: steps.scan.outputs.findings_exist == 'true'
        with:
          name: 04-analysis-report
          path: |
            outputs/analysis_report.txt
            outputs/confirmed_secrets.json
          retention-days: 30

      # ============================================
      # 8. 자동 대응 (다중 시크릿 처리)
      # - AWS 키: 자동 비활성화
      # - 일반 시크릿: 정보 수집
      # ============================================
      - name: Auto-Remediate Secrets
        id: remediation
        if: steps.check_ai_results.outputs.secrets_detected == 'true'
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |
          echo " Running multi-secret remediation module..."
          
          # 자동 대응 실행 및 결과 저장
          python src/remediate_keys.py \
            --results-file predictions.json \
            --mode ai-filtered \
            --output outputs/remediation_results.json 2>&1 | tee outputs/remediation_log.txt
          
          # 대응 완료 시간 기록
          echo "" >> outputs/remediation_log.txt
          echo "Remediation completed at: $(date -u +"%Y-%m-%d %H:%M:%S UTC")" >> outputs/remediation_log.txt
          
          # 결과 파일 존재 확인
          if [ -f "outputs/remediation_results.json" ]; then
            echo " Remediation results saved successfully"
            cat outputs/remediation_results.json | jq '.'
          else
            echo " Warning: remediation_results.json not found"
          fi

      # ============================================
      #  Artifact: 자동 대응 결과 및 로그
      # ============================================
      - name: Upload Remediation Results
        uses: actions/upload-artifact@v4
        if: steps.check_ai_results.outputs.secrets_detected == 'true'
        with:
          name: 05-remediation-results
          path: |
            outputs/remediation_results.json
            outputs/remediation_log.txt
          retention-days: 90

      # ============================================
      # 9. Slack 알림 (다중 시크릿 보고)
      # - remediation_results.json을 사용하여 통합 알림
      # ============================================
      - name: Send Multi-Secret Incident Report to Slack
        if: steps.check_ai_results.outputs.secrets_detected == 'true'
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        run: |
          echo " Sending multi-secret incident report to Slack..."
          
          # remediation_results.json을 Slack 알림에 전달
          python src/notify_slack.py \
            --mode incident \
            --results-file outputs/remediation_results.json 2>&1 | tee outputs/slack_notification_log.txt

      # ============================================
      #  Artifact: Slack 알림 로그
      # ============================================
      - name: Upload Slack Notification Log
        uses: actions/upload-artifact@v4
        if: steps.check_ai_results.outputs.secrets_detected == 'true'
        with:
          name: 06-slack-notification-log
          path: outputs/slack_notification_log.txt
          retention-days: 30

      # ============================================
      #  최종 Artifact: 전체 outputs 디렉토리
      # ============================================
      - name: Upload All Pipeline Outputs
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: complete-pipeline-outputs
          path: outputs/
          retention-days: 90